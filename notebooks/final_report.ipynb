{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dementia Classification (Audio + ASR Text)\n",
        "\n",
        "## Abstract\n",
        "*(Write one paragraph: problem, data source, methods, and the insights you plan to extract.)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "## Problem Addressed\n",
        "\n",
        "## Motivation\n",
        "\n",
        "## Previous Work\n",
        "\n",
        "## Dataset + EDA\n",
        "\n",
        "## Project Schedule and Budget\n",
        "\n",
        "## Technical Approach\n",
        "\n",
        "## Main Results\n",
        "\n",
        "## Explainability + Robustness\n",
        "\n",
        "## Discussion\n",
        "\n",
        "## Future Work\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep code minimal in the notebook; import from dementia_project/ modules.\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_metrics(run_dir: str) -> dict:\n",
        "    return json.loads(Path(run_dir, \"metrics.json\").read_text())\n",
        "\n",
        "\n",
        "runs = {\n",
        "    \"nonml_scaled\": \"runs/nonml_baseline_scaled\",\n",
        "    \"wav2vec2_full_cuda\": \"runs/wav2vec2_baseline_full_cuda\",\n",
        "    \"densenet_full_cuda\": \"runs/densenet_spec_full_cuda\",\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, rdir in runs.items():\n",
        "    m = load_metrics(rdir)\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"model\": name,\n",
        "                \"split\": split,\n",
        "                \"accuracy\": m[split].get(\"accuracy\"),\n",
        "                \"f1\": m[split].get(\"f1\"),\n",
        "                \"roc_auc\": m[split].get(\"roc_auc\"),\n",
        "            }\n",
        "        )\n",
        "\n",
        "df_results = pd.DataFrame(rows)\n",
        "df_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step-by-step: What code runs (module-by-module)\n",
        "\n",
        "This section is a **walkthrough of every Python module** in `dementia_project/`, in the order we run them.\n",
        "\n",
        "### 0) Project entrypoints (where things live)\n",
        "- Code package: `dementia_project/`\n",
        "- Config: `configs/default.yaml`\n",
        "- Processed artifacts: `data/processed/`\n",
        "- Experiment outputs: `runs/`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Build metadata (audio inventory + join to CSV)\n",
        "**Module**: `dementia_project/data/build_metadata.py`\n",
        "\n",
        "**What it does**\n",
        "- Scans both class folders for `.wav`\n",
        "- Computes audio duration/sample rate\n",
        "- Joins dementia-side subjects to `DementiaNet - dementia.csv`\n",
        "- Assigns control subjects from folder names\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/metadata.csv`\n",
        "- `data/processed/dropped.csv`\n",
        "- `data/processed/metadata_report.json`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.data.build_metadata \\\n",
        "  --dementia_dir \"dementia-20251217T041331Z-1-001\" \\\n",
        "  --control_dir \"nodementia-20251217T041501Z-1-001\" \\\n",
        "  --dementia_csv \"DementiaNet - dementia.csv\" \\\n",
        "  --out_dir \"data/processed\"\n",
        "```\n",
        "\n",
        "**Helper used**\n",
        "- `dementia_project/data/name_normalize.py`: `normalize_person_name()` used for robust matching.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Build splits (subject-level train/valid/test)\n",
        "**Modules**\n",
        "- `dementia_project/data/splitting.py`: implements the hybrid split logic.\n",
        "- `dementia_project/data/build_splits.py`: CLI wrapper that writes outputs.\n",
        "\n",
        "**What it does**\n",
        "- Creates `train/valid/test` splits\n",
        "- Enforces **subject-level separation** using `person_name_norm`\n",
        "- Uses CSV `datasplit` when available; otherwise assigns deterministically\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/splits.csv`\n",
        "- `data/processed/splits_report.json`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.data.build_splits \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed\"\n",
        "```\n",
        "\n",
        "**Small I/O helpers**\n",
        "- `dementia_project/data/io.py`: `load_metadata()` and `load_splits()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Segmentation manifests (time windows)\n",
        "**Modules**\n",
        "- `dementia_project/segmentation/time_windows.py`: generates window start/end times.\n",
        "- `dementia_project/segmentation/build_manifests.py`: CLI wrapper that writes outputs.\n",
        "\n",
        "**What it does**\n",
        "- Creates fixed-length windows (e.g., 2s with 0.5s hop) for audio baselines.\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/time_segments.csv`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.segmentation.build_manifests \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"data/processed\" \\\n",
        "  --window_sec 2.0 \\\n",
        "  --hop_sec 0.5\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Baseline 1 — Non-ML audio (MFCC + pause stats)\n",
        "**Modules**\n",
        "- `dementia_project/features/audio_features.py`: MFCC + RMS + pause proxy features\n",
        "- `dementia_project/train/train_nonml.py`: trains/evaluates Logistic Regression baseline\n",
        "\n",
        "**Produces**\n",
        "- `runs/nonml_baseline_scaled/metrics.json`\n",
        "- `runs/nonml_baseline_scaled/confusion_matrix_test.png`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_nonml \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/nonml_baseline_scaled\"\n",
        "```\n",
        "\n",
        "**Plot helper**\n",
        "- `dementia_project/viz/metrics.py`: writes the confusion matrix PNG.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5) Baseline 2 — Audio-only Wav2Vec2 embeddings\n",
        "**Modules**\n",
        "- `dementia_project/features/wav2vec2_embed.py`: loads Wav2Vec2 + mean-pools embeddings\n",
        "- `dementia_project/train/train_wav2vec2_nonml.py`: trains/evaluates sklearn classifier on embeddings\n",
        "\n",
        "**Produces**\n",
        "- `runs/wav2vec2_baseline_full_cuda/metrics.json`\n",
        "- `runs/wav2vec2_baseline_full_cuda/confusion_matrix_test.png`\n",
        "\n",
        "**Command (full dataset)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_wav2vec2_nonml \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/wav2vec2_baseline_full_cuda\" \\\n",
        "  --max_audio_sec 10\n",
        "```\n",
        "\n",
        "**Note on CUDA**\n",
        "- We switched Poetry’s torch to CUDA (`torch 2.6.0+cu124`), so embedding extraction uses the GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6) Baseline 3 — DenseNet on spectrograms\n",
        "**Modules**\n",
        "- `dementia_project/features/spectrograms.py`: creates log-mel spectrogram tensors\n",
        "- `dementia_project/train/train_densenet_spec.py`: trains/evaluates DenseNet baseline\n",
        "\n",
        "**Produces**\n",
        "- `runs/densenet_spec_full_cuda/metrics.json`\n",
        "- `runs/densenet_spec_full_cuda/confusion_matrix_test.png`\n",
        "\n",
        "**Command (full dataset)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_densenet_spec \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/densenet_spec_full_cuda\" \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 16 \\\n",
        "  --max_audio_sec 8\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7) ASR (audio → transcript + word timestamps)\n",
        "**Modules**\n",
        "- `dementia_project/asr/transcribe.py`: Whisper ASR backend (transformers pipeline) producing `words.json`\n",
        "- `dementia_project/asr/run_asr.py`: CLI runner + caching + `asr_manifest.csv`\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/asr_whisper/<audio_id>/transcript.json`\n",
        "- `data/processed/asr_whisper/<audio_id>/words.json`\n",
        "- `data/processed/asr_whisper/asr_manifest.csv`\n",
        "\n",
        "**Command (example sanity run)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.asr.run_asr \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed/asr_whisper\" \\\n",
        "  --limit 5 \\\n",
        "  --model_name \"openai/whisper-tiny\" \\\n",
        "  --language en \\\n",
        "  --task transcribe\n",
        "```\n",
        "\n",
        "**Command (full run, resumable)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.asr.run_asr \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed/asr_whisper\" \\\n",
        "  --model_name \"openai/whisper-tiny\" \\\n",
        "  --language en \\\n",
        "  --task transcribe\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8) (Next) Text-only + Fusion model\n",
        "We will add next:\n",
        "- **Text-only baseline**: Transformer classifier on `transcript.json`\n",
        "- **Fusion model**: cross-attention between text embeddings and word-level audio embeddings\n",
        "\n",
        "Planned new modules will live under:\n",
        "- `dementia_project/models/`\n",
        "- `dementia_project/train/`\n",
        "- `dementia_project/segmentation/` (word-level segments derived from `words.json`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
