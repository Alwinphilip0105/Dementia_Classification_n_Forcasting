{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dementia Classification (Audio + ASR Text)\n",
        "\n",
        "## Abstract\n",
        "*(Write one paragraph: problem, data source, methods, and the insights you plan to extract.)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "## Problem Addressed\n",
        "\n",
        "## Motivation\n",
        "\n",
        "## Previous Work\n",
        "\n",
        "## Dataset + EDA\n",
        "\n",
        "## Project Schedule and Budget\n",
        "\n",
        "## Technical Approach\n",
        "\n",
        "## Main Results\n",
        "\n",
        "## Explainability + Robustness\n",
        "\n",
        "## Discussion\n",
        "\n",
        "## Future Work\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep code minimal in the notebook; import from dementia_project/ modules.\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_metrics(run_dir: str) -> dict:\n",
        "    return json.loads(Path(run_dir, \"metrics.json\").read_text())\n",
        "\n",
        "\n",
        "runs = {\n",
        "    \"nonml_scaled\": \"runs/nonml_baseline_scaled\",\n",
        "    \"wav2vec2_full_cuda\": \"runs/wav2vec2_baseline_full_cuda\",\n",
        "    \"densenet_full_cuda\": \"runs/densenet_spec_full_cuda\",\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, rdir in runs.items():\n",
        "    m = load_metrics(rdir)\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"model\": name,\n",
        "                \"split\": split,\n",
        "                \"accuracy\": m[split].get(\"accuracy\"),\n",
        "                \"f1\": m[split].get(\"f1\"),\n",
        "                \"roc_auc\": m[split].get(\"roc_auc\"),\n",
        "            }\n",
        "        )\n",
        "\n",
        "df_results = pd.DataFrame(rows)\n",
        "df_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step-by-step: What code runs (module-by-module)\n",
        "\n",
        "This section is a **walkthrough of every Python module** in `dementia_project/`, in the order we run them.\n",
        "\n",
        "### 0) Project entrypoints (where things live)\n",
        "- Code package: `dementia_project/`\n",
        "- Config: `configs/default.yaml`\n",
        "- Processed artifacts: `data/processed/`\n",
        "- Experiment outputs: `runs/`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Build metadata (audio inventory + join to CSV)\n",
        "**Module**: `dementia_project/data/build_metadata.py`\n",
        "\n",
        "**What it does**\n",
        "- Scans both class folders for `.wav`\n",
        "- Computes audio duration/sample rate\n",
        "- Joins dementia-side subjects to `DementiaNet - dementia.csv`\n",
        "- Assigns control subjects from folder names\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/metadata.csv`\n",
        "- `data/processed/dropped.csv`\n",
        "- `data/processed/metadata_report.json`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.data.build_metadata \\\n",
        "  --dementia_dir \"dementia-20251217T041331Z-1-001\" \\\n",
        "  --control_dir \"nodementia-20251217T041501Z-1-001\" \\\n",
        "  --dementia_csv \"DementiaNet - dementia.csv\" \\\n",
        "  --out_dir \"data/processed\"\n",
        "```\n",
        "\n",
        "**Helper used**\n",
        "- `dementia_project/data/name_normalize.py`: `normalize_person_name()` used for robust matching.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Build splits (subject-level train/valid/test)\n",
        "**Modules**\n",
        "- `dementia_project/data/splitting.py`: implements the hybrid split logic.\n",
        "- `dementia_project/data/build_splits.py`: CLI wrapper that writes outputs.\n",
        "\n",
        "**What it does**\n",
        "- Creates `train/valid/test` splits\n",
        "- Enforces **subject-level separation** using `person_name_norm`\n",
        "- Uses CSV `datasplit` when available; otherwise assigns deterministically\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/splits.csv`\n",
        "- `data/processed/splits_report.json`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.data.build_splits \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed\"\n",
        "```\n",
        "\n",
        "**Small I/O helpers**\n",
        "- `dementia_project/data/io.py`: `load_metadata()` and `load_splits()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Segmentation manifests (time windows)\n",
        "**Modules**\n",
        "- `dementia_project/segmentation/time_windows.py`: generates window start/end times.\n",
        "- `dementia_project/segmentation/build_manifests.py`: CLI wrapper that writes outputs.\n",
        "\n",
        "**What it does**\n",
        "- Creates fixed-length windows (e.g., 2s with 0.5s hop) for audio baselines.\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/time_segments.csv`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.segmentation.build_manifests \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"data/processed\" \\\n",
        "  --window_sec 2.0 \\\n",
        "  --hop_sec 0.5\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Baseline 1 — Non-ML audio (MFCC + pause stats)\n",
        "**Modules**\n",
        "- `dementia_project/features/audio_features.py`: MFCC + RMS + pause proxy features\n",
        "- `dementia_project/train/train_nonml.py`: trains/evaluates Logistic Regression baseline\n",
        "\n",
        "**Produces**\n",
        "- `runs/nonml_baseline_scaled/metrics.json`\n",
        "- `runs/nonml_baseline_scaled/confusion_matrix_test.png`\n",
        "\n",
        "**Command**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_nonml \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/nonml_baseline_scaled\"\n",
        "```\n",
        "\n",
        "**Plot helper**\n",
        "- `dementia_project/viz/metrics.py`: writes the confusion matrix PNG.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5) Baseline 2 — Audio-only Wav2Vec2 embeddings\n",
        "**Modules**\n",
        "- `dementia_project/features/wav2vec2_embed.py`: loads Wav2Vec2 + mean-pools embeddings\n",
        "- `dementia_project/train/train_wav2vec2_nonml.py`: trains/evaluates sklearn classifier on embeddings\n",
        "\n",
        "**Produces**\n",
        "- `runs/wav2vec2_baseline_full_cuda/metrics.json`\n",
        "- `runs/wav2vec2_baseline_full_cuda/confusion_matrix_test.png`\n",
        "\n",
        "**Command (full dataset)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_wav2vec2_nonml \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/wav2vec2_baseline_full_cuda\" \\\n",
        "  --max_audio_sec 10\n",
        "```\n",
        "\n",
        "**Note on CUDA**\n",
        "- We switched Poetry’s torch to CUDA (`torch 2.6.0+cu124`), so embedding extraction uses the GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6) Baseline 3 — DenseNet on spectrograms\n",
        "**Modules**\n",
        "- `dementia_project/features/spectrograms.py`: creates log-mel spectrogram tensors\n",
        "- `dementia_project/train/train_densenet_spec.py`: trains/evaluates DenseNet baseline\n",
        "\n",
        "**Produces**\n",
        "- `runs/densenet_spec_full_cuda/metrics.json`\n",
        "- `runs/densenet_spec_full_cuda/confusion_matrix_test.png`\n",
        "\n",
        "**Command (full dataset)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_densenet_spec \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --splits_csv \"data/processed/splits.csv\" \\\n",
        "  --out_dir \"runs/densenet_spec_full_cuda\" \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 16 \\\n",
        "  --max_audio_sec 8\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7) ASR (audio → transcript + word timestamps)\n",
        "**Modules**\n",
        "- `dementia_project/asr/transcribe.py`: Whisper ASR backend (transformers pipeline) producing `words.json`\n",
        "- `dementia_project/asr/run_asr.py`: CLI runner + caching + `asr_manifest.csv`\n",
        "\n",
        "**Produces**\n",
        "- `data/processed/asr_whisper/<audio_id>/transcript.json`\n",
        "- `data/processed/asr_whisper/<audio_id>/words.json`\n",
        "- `data/processed/asr_whisper/asr_manifest.csv`\n",
        "\n",
        "**Command (example sanity run)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.asr.run_asr \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed/asr_whisper\" \\\n",
        "  --limit 5 \\\n",
        "  --model_name \"openai/whisper-tiny\" \\\n",
        "  --language en \\\n",
        "  --task transcribe\n",
        "```\n",
        "\n",
        "**Command (full run, resumable)**\n",
        "```bash\n",
        "poetry run python -m dementia_project.asr.run_asr \\\n",
        "  --metadata_csv \"data/processed/metadata.csv\" \\\n",
        "  --out_dir \"data/processed/asr_whisper\" \\\n",
        "  --model_name \"openai/whisper-tiny\" \\\n",
        "  --language en \\\n",
        "  --task transcribe\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8) Text-only + Fusion model\n",
        "We will add next:\n",
        "- **Text-only baseline**: Transformer classifier on `transcript.json`\n",
        "- **Fusion model**: cross-attention between text embeddings and word-level audio embeddings\n",
        "\n",
        "Planned new modules will live under:\n",
        "- `dementia_project/models/`\n",
        "- `dementia_project/train/`\n",
        "- `dementia_project/segmentation/` (word-level segments derived from `words.json`)\n",
        "\n",
        "Here we will fine-tune a BERT model (configured so we can tryout distilled ) to classify our transcripts as dementia or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can run this in bash with:\n",
        "\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_text_baseline \\\n",
        "    --metadata_csv data/processed/metadata.csv \\\n",
        "    --splits_csv data/processed/splits.csv \\\n",
        "    --asr_manifest_csv data/processed/asr_whisper/asr_manifest.csv \\\n",
        "    --out_dir runs/text_baseline \\\n",
        "    --epochs 3 \\\n",
        "    --batch_size 16\n",
        "```\n",
        "\n",
        "or if you want to test on a smaller batch\n",
        "\n",
        "```bash\n",
        "poetry run python -m dementia_project.train.train_text_baseline \\\n",
        "    --metadata_csv data/processed/metadata.csv \\\n",
        "    --splits_csv data/processed/splits.csv \\\n",
        "    --asr_manifest_csv data/processed/asr_whisper/asr_manifest.csv \\\n",
        "    --out_dir runs/text_baseline \\\n",
        "    --epochs 3 \\\n",
        "    --batch_size 16\n",
        "```\n",
        "\n",
        "## Preferrably run the Cells Below\n",
        "\n",
        "at this point I have also realized that the test set is majorly imbalanced, I want to check that the training set is not as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== FILE-LEVEL CLASS DISTRIBUTION ===\n",
            "\n",
            "TRAIN:\n",
            "  No Dementia (0): 156\n",
            "  Dementia (1):    108\n",
            "  Total: 264\n",
            "  Dementia %: 40.9%\n",
            "\n",
            "VALID:\n",
            "  No Dementia (0): 29\n",
            "  Dementia (1):    20\n",
            "  Total: 49\n",
            "  Dementia %: 40.8%\n",
            "\n",
            "TEST:\n",
            "  No Dementia (0): 45\n",
            "  Dementia (1):    3\n",
            "  Total: 48\n",
            "  Dementia %: 6.2%\n",
            "\n",
            "=== SUBJECT-LEVEL CLASS DISTRIBUTION ===\n",
            "\n",
            "TRAIN (unique subjects):\n",
            "  No Dementia (0): 69 subjects\n",
            "  Dementia (1):    68 subjects\n",
            "  Total: 137 subjects\n",
            "\n",
            "VALID (unique subjects):\n",
            "  No Dementia (0): 13 subjects\n",
            "  Dementia (1):    14 subjects\n",
            "  Total: 27 subjects\n",
            "\n",
            "TEST (unique subjects):\n",
            "  No Dementia (0): 18 subjects\n",
            "  Dementia (1):    2 subjects\n",
            "  Total: 20 subjects\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "metadata = pd.read_csv(\"../data/processed/metadata.csv\")\n",
        "splits = pd.read_csv(\"../data/processed/splits.csv\")\n",
        "df = metadata.merge(splits[[\"audio_path\", \"split\"]], on=\"audio_path\")\n",
        "\n",
        "\n",
        "print(\"=== FILE-LEVEL CLASS DISTRIBUTION ===\\n\")\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    subset = df[df[\"split\"] == split]\n",
        "    counts = subset[\"label\"].value_counts().sort_index()\n",
        "    print(f\"{split.upper()}:\")\n",
        "    print(f\"  No Dementia (0): {counts.get(0, 0)}\")\n",
        "    print(f\"  Dementia (1):    {counts.get(1, 0)}\")\n",
        "    print(f\"  Total: {len(subset)}\")\n",
        "    print(f\"  Dementia %: {subset['label'].mean()*100:.1f}%\\n\")\n",
        "\n",
        "print(\"=== SUBJECT-LEVEL CLASS DISTRIBUTION ===\\n\")\n",
        "subject_splits = df.groupby(\"person_name_norm\").agg({\n",
        "    \"split\": \"first\",\n",
        "    \"label\": \"first\"\n",
        "}).reset_index()\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    subset = subject_splits[subject_splits[\"split\"] == split]\n",
        "    counts = subset[\"label\"].value_counts().sort_index()\n",
        "    print(f\"{split.upper()} (unique subjects):\")\n",
        "    print(f\"  No Dementia (0): {counts.get(0, 0)} subjects\")\n",
        "    print(f\"  Dementia (1):    {counts.get(1, 0)} subjects\")\n",
        "    print(f\"  Total: {len(subset)} subjects\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT BASELINE RESULTS ===\n",
            "\n",
            "TRAIN:\n",
            "  Accuracy: 0.928\n",
            "  F1: 0.919\n",
            "  ROC AUC: 0.9798397688468611\n",
            "  Confusion Matrix:\n",
            "    [[TN=129, FP=12],\n",
            "     [FN=6, TP=102]]\n",
            "  Class distribution:\n",
            "    Dementia cases: 108\n",
            "    Control cases: 141\n",
            "  Sensitivity (Recall): 0.944\n",
            "  Specificity: 0.915\n",
            "\n",
            "VALID:\n",
            "  Accuracy: 0.630\n",
            "  F1: 0.485\n",
            "  ROC AUC: 0.648076923076923\n",
            "  Confusion Matrix:\n",
            "    [[TN=21, FP=5],\n",
            "     [FN=12, TP=8]]\n",
            "  Class distribution:\n",
            "    Dementia cases: 20\n",
            "    Control cases: 26\n",
            "  Sensitivity (Recall): 0.400\n",
            "  Specificity: 0.808\n",
            "\n",
            "TEST:\n",
            "  Accuracy: 0.652\n",
            "  F1: 0.111\n",
            "  ROC AUC: 0.4728682170542635\n",
            "  Confusion Matrix:\n",
            "    [[TN=29, FP=14],\n",
            "     [FN=2, TP=1]]\n",
            "  Class distribution:\n",
            "    Dementia cases: 3\n",
            "    Control cases: 43\n",
            "  Sensitivity (Recall): 0.333\n",
            "  Specificity: 0.674\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Load metrics from previous runs\n",
        "with open(\"../runs/text_baseline/metrics.json\") as f:\n",
        "    text_metrics = json.load(f)\n",
        "\n",
        "print(\"=== TEXT BASELINE RESULTS ===\\n\")\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    m = text_metrics[split]\n",
        "    cm = m[\"confusion_matrix\"]\n",
        "\n",
        "    # dditional metrics for true/false positive analysis\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    total_positive = tp + fn  # actual dementia cases\n",
        "    total_negative = tn + fp  # actual control cases\n",
        "\n",
        "    print(f\"{split.upper()}:\")\n",
        "    print(f\"  Accuracy: {m['accuracy']:.3f}\")\n",
        "    print(f\"  F1: {m['f1']:.3f}\")\n",
        "    print(f\"  ROC AUC: {m.get('roc_auc', 'N/A')}\")\n",
        "    print(f\"  Confusion Matrix:\")\n",
        "    print(f\"    [[TN={tn}, FP={fp}],\")\n",
        "    print(f\"     [FN={fn}, TP={tp}]]\")\n",
        "    print(f\"  Class distribution:\")\n",
        "    print(f\"    Dementia cases: {total_positive}\")\n",
        "    print(f\"    Control cases: {total_negative}\")\n",
        "\n",
        "    if total_positive > 0:\n",
        "        print(f\"  Sensitivity (Recall): {tp/total_positive:.3f}\")\n",
        "    if total_negative > 0:\n",
        "        print(f\"  Specificity: {tn/total_negative:.3f}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
